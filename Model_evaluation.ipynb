{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda31693",
   "metadata": {},
   "source": [
    "# $Model Evaluation $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f212c8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a66b4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ea5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e6896fb",
   "metadata": {},
   "source": [
    "# 2. \n",
    "Given the following confusion matrix, evaluate (by hand) the model's performance.\n",
    "\n",
    "Dog is positive\n",
    "\n",
    "Cat is negative\n",
    "\n",
    "|               | pred dog   | pred cat   |\n",
    "|:------------  |-----------:|-----------:|\n",
    "| actual dog    |         46 |         7  |\n",
    "| actual cat    |         13 |         34 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ccd8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculations (tp,fp,fn,tn):\n",
    "    '''This function takes in integers for true positive, false positive, false negative, true negative\n",
    "    and returns accuracy, recall, precision, and baseline choosing dog.'''\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp/ (tp + fp)\n",
    "    baseline = (tp+tn)/(tp + tp + fn + tn)\n",
    "    \n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Recall:', recall)\n",
    "    print('Precision:', precision)\n",
    "    print('Baseline:',baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d03e078d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Recall: 0.8679245283018868\n",
      "Precision: 0.7796610169491526\n",
      "Baseline: 0.6015037593984962\n"
     ]
    }
   ],
   "source": [
    "calculations (46,13,7,34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bf88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 46\n",
    "tn = 34\n",
    "fp = 13\n",
    "fn = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6b37a",
   "metadata": {},
   "source": [
    "In the context of this problem, what is a false positive?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f0fd8",
   "metadata": {},
   "source": [
    "predicted dog, actual cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0397ff",
   "metadata": {},
   "source": [
    "In the context of this problem, what is a false negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fe4b3",
   "metadata": {},
   "source": [
    "predicted cat, actual dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad38513",
   "metadata": {},
   "source": [
    "How would you describe this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86064ae5",
   "metadata": {},
   "source": [
    "The models accuracy, recall and precision is good because it is above the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d0201",
   "metadata": {},
   "source": [
    "### 3. \n",
    "You are working as a datascientist working for Codeup Cody Creator (C3 for short), a rubber-duck manufacturing plant.\n",
    "\n",
    "Unfortunately, some of the rubber ducks that are produced will have defects. Your team has built several models that try to predict those defects, and the data from their predictions can be found here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "505e1db1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual     model1     model2     model3\n",
       "78   No Defect  No Defect  No Defect  No Defect\n",
       "36   No Defect  No Defect     Defect  No Defect\n",
       "47   No Defect  No Defect  No Defect  No Defect\n",
       "128  No Defect  No Defect  No Defect     Defect\n",
       "187  No Defect  No Defect  No Defect     Defect\n",
       "23   No Defect  No Defect  No Defect     Defect\n",
       "181  No Defect  No Defect     Defect  No Defect\n",
       "189  No Defect  No Defect  No Defect  No Defect\n",
       "30      Defect     Defect  No Defect     Defect\n",
       "58   No Defect  No Defect     Defect  No Defect"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3 = pd.read_csv('c3.csv')\n",
    "c3.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7012825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Defect    184\n",
       "Defect        16\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4d4bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   actual  200 non-null    object\n",
      " 1   model1  200 non-null    object\n",
      " 2   model2  200 non-null    object\n",
      " 3   model3  200 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "c3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf02850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      No Defect\n",
       "1      No Defect\n",
       "2      No Defect\n",
       "3      No Defect\n",
       "4      No Defect\n",
       "         ...    \n",
       "195    No Defect\n",
       "196       Defect\n",
       "197    No Defect\n",
       "198    No Defect\n",
       "199    No Defect\n",
       "Name: actual, Length: 200, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3.actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e064423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode 1               precision    recall  f1-score   support\n",
      "\n",
      "      Defect       0.80      0.50      0.62        16\n",
      "   No Defect       0.96      0.99      0.97       184\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.88      0.74      0.79       200\n",
      "weighted avg       0.95      0.95      0.94       200\n",
      "\n",
      "model 2               precision    recall  f1-score   support\n",
      "\n",
      "      Defect       0.10      0.56      0.17        16\n",
      "   No Defect       0.94      0.56      0.70       184\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.52      0.56      0.44       200\n",
      "weighted avg       0.87      0.56      0.66       200\n",
      "\n",
      "model 3               precision    recall  f1-score   support\n",
      "\n",
      "      Defect       0.13      0.81      0.23        16\n",
      "   No Defect       0.97      0.53      0.69       184\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.55      0.67      0.46       200\n",
      "weighted avg       0.90      0.56      0.65       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('mode 1',classification_report(c3.actual, c3.model1))\n",
    "print('model 2',classification_report(c3.actual, c3.model2))\n",
    "print('model 3',classification_report(c3.actual, c3.model3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c900d",
   "metadata": {},
   "source": [
    "* An internal team wants to investigate the cause of the manufacturing defects. They tell you that they want to identify as many of the ducks that have a defect as possible. Which evaluation metric would be appropriate here? Which model would be the best fit for this use case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb918a",
   "metadata": {},
   "source": [
    "Positive: duck is defect free\n",
    "\n",
    "Negative: duck has a defect\n",
    "\n",
    "TP: we predict duck is defect free and duck is defect free___\n",
    "FP: we predict duck is defect free and duck is has a defect\n",
    "\n",
    "FN: we predict duck has a defect and duck is defect free___\n",
    "TN: we predict duck has a defect and duck has a defect___\n",
    "\n",
    "\n",
    "\n",
    "|           |    +       |     -      |\n",
    "|:----------|-----------:|-----------:|\n",
    "|      +    |            |            |\n",
    "|           |     TP     |     FP     |\n",
    "|           |            |            |\n",
    "|:----------|-----------:|-----------:|   \n",
    "|           |            |            |\n",
    "|      -    |      FN    |     TN     |\n",
    "|           |            |            |\n",
    "\n",
    "A false positive would be the worst situation. So the best the appropriate metric here would lessen type 1 errors which is ***precision***\n",
    "\n",
    "### **Should be the false negative adjust for  recall and use model 3 !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8ba07",
   "metadata": {},
   "source": [
    "* Recently several stories in the local news have come out highlighting customers who received a rubber duck with a defect, and portraying C3 in a bad light. The PR team has decided to launch a program that gives customers with a defective duck a vacation to Hawaii. They need you to predict which ducks will have defects, but tell you the really don't want to accidentally give out a vacation package when the duck really doesn't have a defect. Which evaluation metric would be appropriate here? Which model would be the best fit for this use case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc161f",
   "metadata": {},
   "source": [
    "A false positive would be the worst situation. So the best the appropriate metric here would lessen type 1 errors which is ***precision**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f94bb",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645a2ee",
   "metadata": {},
   "source": [
    "You are working as a data scientist for Gives You Paws ™, a subscription based service that shows you cute pictures of dogs or cats (or both for an additional fee).\n",
    "\n",
    "At Gives You Paws, anyone can upload pictures of their cats or dogs. The photos are then put through a two step process. First an automated algorithm tags pictures as either a cat or a dog (Phase I). Next, the photos that have been initially identified are put through another round of review, possibly with some human oversight, before being presented to the users (Phase II).\n",
    "\n",
    "Several models have already been developed with the data, and you can find their results here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403cc78",
   "metadata": {},
   "source": [
    "Given this dataset, use pandas to create a baseline model (i.e. a model that just predicts the most common class) and answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d7296",
   "metadata": {},
   "source": [
    "Positive: It is a dog\n",
    "\n",
    "Negative: it is not a dog\n",
    "\n",
    "TP: Predicted a dog and it was a dog\n",
    "\n",
    "FP: Predicted a dog and it was not a dog\n",
    "\n",
    "FN: Predicted it was not a dog and it was a dog\n",
    "\n",
    "TN: Predicted it was not a dog ant it was not a dog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c3f533f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3606</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual model1 model2 model3 model4\n",
       "3606    dog    cat    dog    cat    dog\n",
       "1637    dog    dog    cat    dog    cat\n",
       "757     cat    cat    cat    dog    cat\n",
       "746     cat    cat    cat    dog    dog\n",
       "1293    dog    dog    cat    cat    dog\n",
       "3941    dog    dog    cat    cat    dog\n",
       "161     cat    cat    cat    dog    cat\n",
       "3143    cat    cat    cat    dog    dog\n",
       "4497    dog    dog    cat    cat    dog\n",
       "1512    dog    cat    cat    cat    dog"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paw = pd.read_csv('gives_you_paws.csv')\n",
    "paw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36379d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog    3254\n",
       "cat    1746\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paw.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8c494ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual model1 model2 model3 model4 baseline\n",
       "0       cat    cat    dog    cat    dog      dog\n",
       "1       dog    dog    cat    cat    dog      dog\n",
       "2       dog    cat    cat    cat    dog      dog\n",
       "3       dog    dog    dog    cat    dog      dog\n",
       "4       cat    cat    cat    dog    dog      dog\n",
       "...     ...    ...    ...    ...    ...      ...\n",
       "4995    dog    dog    dog    dog    dog      dog\n",
       "4996    dog    dog    cat    cat    dog      dog\n",
       "4997    dog    cat    cat    dog    dog      dog\n",
       "4998    cat    cat    cat    cat    dog      dog\n",
       "4999    dog    dog    dog    dog    dog      dog\n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paw['baseline'] = 'dog'\n",
    "# good to do it programaticaly, avoid assigning values, get them programatically\n",
    "\n",
    "# paw['baseline'] = paw.actual.value_counts().idxmax\n",
    "paw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfffd1f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode 1               precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.69      0.82      0.75      1746\n",
      "         dog       0.89      0.80      0.84      3254\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.79      0.81      0.80      5000\n",
      "weighted avg       0.82      0.81      0.81      5000\n",
      "\n",
      "model 2               precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.48      0.89      0.63      1746\n",
      "         dog       0.89      0.49      0.63      3254\n",
      "\n",
      "    accuracy                           0.63      5000\n",
      "   macro avg       0.69      0.69      0.63      5000\n",
      "weighted avg       0.75      0.63      0.63      5000\n",
      "\n",
      "model 3               precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.36      0.51      0.42      1746\n",
      "         dog       0.66      0.51      0.57      3254\n",
      "\n",
      "    accuracy                           0.51      5000\n",
      "   macro avg       0.51      0.51      0.50      5000\n",
      "weighted avg       0.55      0.51      0.52      5000\n",
      "\n",
      "model 4               precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.81      0.35      0.48      1746\n",
      "         dog       0.73      0.96      0.83      3254\n",
      "\n",
      "    accuracy                           0.74      5000\n",
      "   macro avg       0.77      0.65      0.66      5000\n",
      "weighted avg       0.76      0.74      0.71      5000\n",
      "\n",
      "baseline               precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.00      0.00      0.00      1746\n",
      "         dog       0.65      1.00      0.79      3254\n",
      "\n",
      "    accuracy                           0.65      5000\n",
      "   macro avg       0.33      0.50      0.39      5000\n",
      "weighted avg       0.42      0.65      0.51      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('mode 1',classification_report(paw.actual, paw.model1))\n",
    "print('model 2',classification_report(paw.actual, paw.model2))\n",
    "print('model 3',classification_report(paw.actual, paw.model3))\n",
    "print('model 4',classification_report(paw.actual, paw.model4))\n",
    "\n",
    "print('baseline',classification_report(paw.actual, paw.baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe24117",
   "metadata": {},
   "source": [
    "### a. In terms of accuracy, how do the various models compare to the baseline model? Are any of the models better than the baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d35d899",
   "metadata": {},
   "source": [
    "Model 1 and Model 4 are above the baseline in terms of accuracy. The other Model 2 and Model 3 are below baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff8b03",
   "metadata": {},
   "source": [
    "### b. Suppose you are working on a team that solely deals with dog pictures. Which of these models would you recommend?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea253c8",
   "metadata": {},
   "source": [
    "FP: Predicted a dog and it was not a dog;\n",
    "would be the worst situation, since we do not want to be sending out pictures that are not dogs.\n",
    "\n",
    "We should optimized for precision and lessen type 1 errors\n",
    "\n",
    "***We should go with Model 1 or Model 2***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a455ce1",
   "metadata": {},
   "source": [
    "### c. Suppose you are working on a team that solely deals with cat pictures. Which of these models would you recommend?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b93b6c",
   "metadata": {},
   "source": [
    "Positive: pic is a cat\n",
    "\n",
    "Negative: pic is not a cat\n",
    "\n",
    "TP: Predicted a cat and it was a cat\n",
    "\n",
    "FP: Predicted a cat and it was not a cat\n",
    "\n",
    "FN: Predicted it was not a cat and it was a cat\n",
    "\n",
    "TN: Predicted it was not a cat ant it was not a cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e0393",
   "metadata": {},
   "source": [
    "Adjust for recall:\n",
    "Use Model 2\n",
    "\n",
    "### *** !!!Model 4 for cats optimized for precision***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79d066",
   "metadata": {},
   "source": [
    " ### 5. Follow the links below to read the documentation about each function, then apply those functions to the data from the previous problem.\n",
    "\n",
    "sklearn.metrics.accuracy_score\n",
    "\n",
    "sklearn.metrics.precision_score\n",
    "\n",
    "sklearn.metrics.recall_score\n",
    "\n",
    "sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5293b85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " accuracy_score(paw.actual, paw.model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c5a63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0b1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
